{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ARMAPS-real-time Object Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EPtldBFZZkrk"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UWI-Capstone-VFalcons/ODModel/blob/main/ARMAPS_real_time_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-KVjA7GrZbS"
      },
      "source": [
        "<img align=\"left\" src=\"https://cdn-images-1.medium.com/max/1200/1*iDQvKoz7gGHc6YXqvqWWZQ.png\" width=\"85\" height=\"80\" >\n",
        "<br>\n",
        "\n",
        "#  Custom Real-Time Object Detection\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "This notebook is part of the tutorial [Custom real-time object detection in the browser using TensorFlow.js](https://medium.com/@zaninihugo/custom-real-time-object-detection-in-the-browser-using-tensorflow-js-5ca90538eace) and aims to train a custom Object Detection model using the TensorFlow 2 Object Detection API.\n",
        "\n",
        "Later, this model is going to be converted to TensorFlow.js  to run directly in a web browser. Refer to the tutorial post to see how."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzZ0iAH--6k6"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaUG3D6m_FEY"
      },
      "source": [
        "### **Clone and install the Tensorflow Object Detection API** \n",
        "\n",
        "In order to use the TensorFlow Object Detection API, we need to clone it's GitHub Repo.\n",
        "<br>\n",
        "\n",
        "#### **Dependencies**\n",
        "\n",
        "\n",
        "Most of the dependencies required come preloaded in Google Colab.  No extra installation is needed.\n",
        "<br>\n",
        "\n",
        "#### **Protocol Buffers**\n",
        "\n",
        "\n",
        "\n",
        "The TensorFlow Object Detection API relies on what are called `protocol buffers` (also known as `protobufs`). Protobufs are a language neutral way to describe information. That means you can write a protobuf once and then compile it to be used with other languages, like Python, Java or C [5].\n",
        "\n",
        "The `protoc` command used below is compiling all the protocol buffers in the `object_detection/protos` folder for Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WuDEEKVGHm_",
        "outputId": "265d5a41-6633-4146-f178-81367b0a760c"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/UWI-Capstone-VFalcons/ODModel.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'ODModel'...\n",
            "remote: Enumerating objects: 669, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 669 (delta 35), reused 114 (delta 35), pack-reused 554\u001b[K\n",
            "Receiving objects: 100% (669/669), 494.79 MiB | 33.65 MiB/s, done.\n",
            "Resolving deltas: 100% (301/301), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCAN24-1GZCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7745377d-5f36-4f3d-a625-198cca040c38"
      },
      "source": [
        "%cd /content/ODModel/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ODModel\n",
            "armaps-od  Custom_real_time_Object_Detection.ipynb  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFXTpUiAJm5P",
        "outputId": "74da9bec-9c3d-4609-d61a-868ac2c7ede8"
      },
      "source": [
        "!git pull origin main"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/UWI-Capstone-VFalcons/ODModel\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbkuAjhU-3e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefe297e-82e0-4a77-a66e-50e3a09b59d4"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 56219, done.\u001b[K\n",
            "remote: Counting objects: 100% (260/260), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 56219 (delta 131), reused 208 (delta 102), pack-reused 55959\u001b[K\n",
            "Receiving objects: 100% (56219/56219), 572.20 MiB | 32.56 MiB/s, done.\n",
            "Resolving deltas: 100% (38748/38748), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2qonPgMGq9B",
        "outputId": "4b43ba4a-e7ca-44d8-8ea0-5050e298bf0f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "armaps-od  Custom_real_time_Object_Detection.ipynb  models  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukzhAgID_gyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2768dfba-b177-41bf-e31e-e37a9d063907"
      },
      "source": [
        "%cd /content/ODModel/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ODModel/models/research\n",
            "Processing /content/ODModel/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
            "Collecting apache-beam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/e7/d6e5a3786d9a037a38af966bf154bcd6cb3cbea2edffda00cf6c417cc9a2/apache_beam-2.28.0-cp37-cp37m-manylinux2010_x86_64.whl (9.0MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.22)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4a/23a08f8fd2747867ee223612e219eeb0d11c36116601d99b55ef3c72e707/tf_models_official-2.4.0-py2.py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.4MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/26/cc1acc339eb1b8423c32b0a1dca524214012e577c22ce8fdd58d5213f9b4/fastavro-1.4.0-cp37-cp37m-manylinux2014_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.3)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy<1.20.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 52.0MB/s \n",
            "\u001b[?25hCollecting mock<3.0.0,>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Collecting pyarrow<3.0.0,>=0.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/8d/c002e27767595f22aa09ed0d364327922f673d12b36526c967a2bf6b2ed7/pyarrow-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 251kB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (54.2.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.4.1)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 39.7MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/6d/92f377bece9b0ec9c893081dbe073a65b38d7ac12ef572b8f70554d08760/opencv_python_headless-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (37.6MB)\n",
            "\u001b[K     |████████████████████████████████| 37.6MB 1.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Collecting pbr>=0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.28.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.3.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.29.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, future, dill, py-cpuinfo, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1643829 sha256=24b79b4a196ba2a63da01787466ce63ac5f95558f0b3561acdb8e9ff25e2fb1d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hsp_e64w/wheels/f8/1c/8f/ebe9a48336ffad076570f676fd5088320a781cbce8e376a696\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=5c1049d704cc9ac79538d42a57fbac666cc9b856b49b39c751106423bb6ae74e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=d4cf7a7302244aab1488ae13a7bf8ade5ef0229dc4a781ebb29cf4300b708e46\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78532 sha256=ba1b72abf18f4ec7375015b07c914c6ad2e86fc6e599704ba7c3bd0bd39a6ef5\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=d39056fec7d178b0a9da7d3a6cc1caa0ed97ec303a009bfa45d7adf6fdb3f339\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=8d0b7c816aeb7e360e2a30e0441866057a0f4a9d7f16297b4cfd80a4b06e11d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built object-detection avro-python3 future dill py-cpuinfo seqeval\n",
            "\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: avro-python3, fastavro, requests, hdfs, future, dill, pbr, mock, pyarrow, apache-beam, tf-slim, lvis, dataclasses, sentencepiece, tensorflow-model-optimization, pyyaml, py-cpuinfo, opencv-python-headless, tensorflow-addons, seqeval, tf-models-official, object-detection\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed apache-beam-2.28.0 avro-python3-1.10.2 dataclasses-0.6 dill-0.3.1.1 fastavro-1.4.0 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.5.1.48 pbr-5.5.1 py-cpuinfo-8.0.0 pyarrow-2.0.0 pyyaml-5.4.1 requests-2.25.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-addons-0.12.1 tensorflow-model-optimization-0.5.0 tf-models-official-2.4.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkZtxPYCXLHu"
      },
      "source": [
        "Run the model builder test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzfZSmpSXMxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b80a7b0-844f-4999-80a9-7ad1b7dbadd9"
      },
      "source": [
        "!python /content/ODModel/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-21 02:09:46.486908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "2021-04-21 02:09:49.867250: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-21 02:09:49.889630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-21 02:09:49.976724: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-21 02:09:49.976785: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c2a0c1b62030): /proc/driver/nvidia/version does not exist\n",
            "2021-04-21 02:09:49.977352: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 0.99s\n",
            "I0421 02:09:50.598713 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 0.99s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.4s\n",
            "I0421 02:09:50.999143 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.4s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0421 02:09:51.000209 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I0421 02:09:51.036150 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0421 02:09:51.061312 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I0421 02:09:51.087902 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.16s\n",
            "I0421 02:09:51.253305 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "I0421 02:09:51.421363 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.17s\n",
            "I0421 02:09:51.596409 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n",
            "I0421 02:09:51.767241 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "I0421 02:09:51.943643 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "I0421 02:09:51.995400 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0421 02:09:52.338356 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0421 02:09:52.338580 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0421 02:09:52.338680 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0421 02:09:52.345023 139975605426048 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0421 02:09:52.403508 139975605426048 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0421 02:09:52.403707 139975605426048 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0421 02:09:52.492986 139975605426048 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0421 02:09:52.493176 139975605426048 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0421 02:09:52.676355 139975605426048 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0421 02:09:52.676579 139975605426048 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0421 02:09:52.872229 139975605426048 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0421 02:09:52.872473 139975605426048 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0421 02:09:53.171330 139975605426048 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0421 02:09:53.171586 139975605426048 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0421 02:09:53.463870 139975605426048 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0421 02:09:53.464079 139975605426048 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0421 02:09:54.038018 139975605426048 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0421 02:09:54.038231 139975605426048 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0421 02:09:54.143143 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0421 02:09:54.210125 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0421 02:09:54.297766 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0421 02:09:54.297962 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0421 02:09:54.298032 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0421 02:09:54.303007 139975605426048 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0421 02:09:54.321223 139975605426048 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0421 02:09:54.321407 139975605426048 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0421 02:09:54.464615 139975605426048 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0421 02:09:54.464808 139975605426048 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0421 02:09:54.752508 139975605426048 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0421 02:09:54.752708 139975605426048 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0421 02:09:55.026279 139975605426048 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0421 02:09:55.026545 139975605426048 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0421 02:09:55.404820 139975605426048 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0421 02:09:55.405028 139975605426048 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0421 02:09:55.804171 139975605426048 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0421 02:09:55.804384 139975605426048 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0421 02:09:56.336205 139975605426048 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0421 02:09:56.336448 139975605426048 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0421 02:09:56.577607 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0421 02:09:56.635467 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0421 02:09:56.730930 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0421 02:09:56.731185 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0421 02:09:56.731306 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0421 02:09:56.737598 139975605426048 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0421 02:09:56.756353 139975605426048 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0421 02:09:56.756556 139975605426048 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0421 02:09:56.899724 139975605426048 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0421 02:09:56.899924 139975605426048 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0421 02:09:57.177855 139975605426048 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0421 02:09:57.178055 139975605426048 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0421 02:09:57.458090 139975605426048 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0421 02:09:57.458292 139975605426048 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0421 02:09:58.007587 139975605426048 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0421 02:09:58.007791 139975605426048 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0421 02:09:58.409350 139975605426048 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0421 02:09:58.409576 139975605426048 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0421 02:09:58.956829 139975605426048 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0421 02:09:58.957028 139975605426048 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0421 02:09:59.201622 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0421 02:09:59.263568 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0421 02:09:59.357804 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0421 02:09:59.358006 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0421 02:09:59.358084 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0421 02:09:59.363918 139975605426048 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0421 02:09:59.383033 139975605426048 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0421 02:09:59.383233 139975605426048 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0421 02:09:59.550331 139975605426048 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0421 02:09:59.550596 139975605426048 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0421 02:09:59.829705 139975605426048 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0421 02:09:59.829902 139975605426048 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0421 02:10:00.121304 139975605426048 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0421 02:10:00.121540 139975605426048 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0421 02:10:00.608814 139975605426048 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0421 02:10:00.609027 139975605426048 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0421 02:10:01.121327 139975605426048 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0421 02:10:01.121548 139975605426048 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0421 02:10:01.859526 139975605426048 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0421 02:10:01.859733 139975605426048 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0421 02:10:02.127281 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0421 02:10:02.195956 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0421 02:10:02.294021 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0421 02:10:02.294230 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0421 02:10:02.294316 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0421 02:10:02.299231 139975605426048 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0421 02:10:02.317278 139975605426048 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0421 02:10:02.317492 139975605426048 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0421 02:10:02.461325 139975605426048 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0421 02:10:02.461595 139975605426048 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0421 02:10:02.824812 139975605426048 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0421 02:10:02.825024 139975605426048 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0421 02:10:03.421966 139975605426048 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0421 02:10:03.422165 139975605426048 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0421 02:10:04.013588 139975605426048 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0421 02:10:04.013795 139975605426048 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0421 02:10:04.663868 139975605426048 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0421 02:10:04.664072 139975605426048 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0421 02:10:05.647658 139975605426048 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0421 02:10:05.647857 139975605426048 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0421 02:10:05.941260 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0421 02:10:06.019338 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0421 02:10:06.128558 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0421 02:10:06.128761 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0421 02:10:06.128826 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0421 02:10:06.133722 139975605426048 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0421 02:10:06.152038 139975605426048 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0421 02:10:06.152248 139975605426048 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0421 02:10:06.388306 139975605426048 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0421 02:10:06.388526 139975605426048 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0421 02:10:06.869364 139975605426048 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0421 02:10:06.869606 139975605426048 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0421 02:10:07.342511 139975605426048 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0421 02:10:07.342717 139975605426048 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0421 02:10:08.064211 139975605426048 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0421 02:10:08.064414 139975605426048 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0421 02:10:08.994070 139975605426048 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0421 02:10:08.994265 139975605426048 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0421 02:10:10.121588 139975605426048 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0421 02:10:10.121791 139975605426048 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0421 02:10:10.645823 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0421 02:10:10.734791 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0421 02:10:10.856900 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0421 02:10:10.857107 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0421 02:10:10.857172 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0421 02:10:10.862082 139975605426048 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0421 02:10:10.879498 139975605426048 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0421 02:10:10.879678 139975605426048 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0421 02:10:11.102369 139975605426048 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0421 02:10:11.102607 139975605426048 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0421 02:10:11.648157 139975605426048 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0421 02:10:11.648355 139975605426048 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0421 02:10:12.231278 139975605426048 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0421 02:10:12.231514 139975605426048 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0421 02:10:13.030948 139975605426048 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0421 02:10:13.031160 139975605426048 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0421 02:10:13.893180 139975605426048 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0421 02:10:13.893390 139975605426048 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0421 02:10:15.662789 139975605426048 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0421 02:10:15.663011 139975605426048 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0421 02:10:16.238039 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0421 02:10:16.329604 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0421 02:10:16.464504 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0421 02:10:16.464704 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0421 02:10:16.464767 139975605426048 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0421 02:10:16.469630 139975605426048 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0421 02:10:16.487512 139975605426048 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0421 02:10:16.487693 139975605426048 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0421 02:10:16.789558 139975605426048 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0421 02:10:16.789818 139975605426048 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0421 02:10:17.452019 139975605426048 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0421 02:10:17.452229 139975605426048 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0421 02:10:18.129990 139975605426048 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0421 02:10:18.130192 139975605426048 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0421 02:10:19.158600 139975605426048 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0421 02:10:19.158795 139975605426048 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0421 02:10:20.295888 139975605426048 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0421 02:10:20.296093 139975605426048 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0421 02:10:22.213845 139975605426048 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0421 02:10:22.214053 139975605426048 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0421 02:10:23.118397 139975605426048 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0421 02:10:23.219776 139975605426048 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.67s\n",
            "I0421 02:10:23.666035 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0421 02:10:23.674649 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0421 02:10:23.676735 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0421 02:10:23.677334 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0421 02:10:23.679095 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0421 02:10:23.680617 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0421 02:10:23.681080 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0421 02:10:23.682160 139975605426048 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 21 tests in 34.074s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIj4L4S1neYu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOgMOdcmOzVc"
      },
      "source": [
        "### Getting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBaiFvhiIrAe"
      },
      "source": [
        "Creatting the test and train csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yIkwN0MCbAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc7dab84-27a9-4498-c39c-cd35aa5ffb36"
      },
      "source": [
        "%cd /content/ODModel/armaps-od/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ODModel/armaps-od\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFNBnB93Ipdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53bd89d-346d-41b1-f623-ba1c8b07ccf0"
      },
      "source": [
        "!python xml_to_csv.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zff5msFLAm8g"
      },
      "source": [
        "##### Converting data to TFRecord\n",
        "The dataset contains two files `train_labels.csv` and `test_labels.csv` which need to be converted into TFRecord format so that it can be fed into Tensorflow’s 2 Object Detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRYscfzGEgl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e6a56e-0d77-4dce-900b-e5da0bdeba0a"
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=records/train.record\n",
        "!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=records/test.record"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-21 02:10:25.812532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Successfully created the TFRecords: /content/ODModel/armaps-od/records/train.record\n",
            "2021-04-21 02:10:28.801228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Successfully created the TFRecords: /content/ODModel/armaps-od/records/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwpHRbZUngms"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mzXmPHfPJsP"
      },
      "source": [
        "### Configuring train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5vys2yVG7_m"
      },
      "source": [
        "We are going to use the pretrained TF2 MobileNet V2 model as the feature extractor in the SSD MobileNet V2 Object Detection model. So the next logical step is to download and untar the pretrained TF2 MobileNet V2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE5PyJUpP7F8"
      },
      "source": [
        "#### Downloading MobileNet weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qafiqrBJG8pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c937b1-bb5e-408c-e9d9-2b514682abf0"
      },
      "source": [
        "%cd /content/ODModel\n",
        "!wget http://download.tensorflow.org/models/object_detection/classification/tf2/20200710/mobilenet_v2.tar.gz\n",
        "!tar -xvf mobilenet_v2.tar.gz\n",
        "!rm mobilenet_v2.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ODModel\n",
            "--2021-04-21 02:10:31--  http://download.tensorflow.org/models/object_detection/classification/tf2/20200710/mobilenet_v2.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.7.240, 2607:f8b0:4004:802::2010\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.7.240|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8404070 (8.0M) [application/x-tar]\n",
            "Saving to: ‘mobilenet_v2.tar.gz’\n",
            "\n",
            "mobilenet_v2.tar.gz 100%[===================>]   8.01M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-04-21 02:10:31 (81.1 MB/s) - ‘mobilenet_v2.tar.gz’ saved [8404070/8404070]\n",
            "\n",
            "mobilenet_v2/\n",
            "mobilenet_v2/mobilenet_v2.ckpt-1.index\n",
            "mobilenet_v2/checkpoint\n",
            "mobilenet_v2/mobilenet_v2.ckpt-1.data-00001-of-00002\n",
            "mobilenet_v2/mobilenet_v2.ckpt-1.data-00000-of-00002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zRvdLDfRGA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8716fcd7-f8c4-475a-8cb6-1ac511e92781"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
        "!mv ssd_mobilenet_v2_320x320_coco17_tpu-8.config mobilenet_v2.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-21 02:10:31--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4484 (4.4K) [text/plain]\n",
            "Saving to: ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.config’\n",
            "\n",
            "\r          ssd_mobil   0%[                    ]       0  --.-KB/s               \rssd_mobilenet_v2_32 100%[===================>]   4.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-21 02:10:31 (48.7 MB/s) - ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.config’ saved [4484/4484]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5gIl9aSVdGq"
      },
      "source": [
        "#### Defining training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVps_k4JRGa7"
      },
      "source": [
        "num_classes = 9 # number of objects to detect\n",
        "batch_size = 96 #16\n",
        "num_steps = 7500 #1500\n",
        "num_eval_steps = 1000\n",
        "\n",
        "train_record_path = '/content/ODModel/armaps-od/records/train.record'\n",
        "test_record_path = '/content/ODModel/armaps-od/records/test.record'\n",
        "model_dir = '/content/ODModel/armaps-od/training/'\n",
        "labelmap_path = '/content/ODModel/armaps-od/training/labelmap.pbtxt'\n",
        "\n",
        "pipeline_config_path = 'mobilenet_v2.config'\n",
        "fine_tune_checkpoint = '/content/ODModel/mobilenet_v2/mobilenet_v2.ckpt-1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOiWE_mCVgap"
      },
      "source": [
        "#### Editing config file\n",
        "\n",
        "The next cell is modification of the code available at [4]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH9pVN4qfbAb"
      },
      "source": [
        "import re\n",
        "\n",
        "with open(pipeline_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open(pipeline_config_path, 'w') as f:\n",
        "\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "  'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "  \n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint),\n",
        "                  config)\n",
        "  \n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "  \n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "  \n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(num_classes), config)\n",
        "  \n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "  \n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "  \n",
        "  f.write(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_FmiIbinigI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHxMKaxfhGyU"
      },
      "source": [
        "### Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dx_wEykfpuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349da3a1-5805-464f-c29a-bb8f30c1a661"
      },
      "source": [
        "!python /content/ODModel/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-21 02:10:32.504699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-21 02:10:35.401909: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-21 02:10:35.402922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-21 02:10:35.414180: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-21 02:10:35.414235: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c2a0c1b62030): /proc/driver/nvidia/version does not exist\n",
            "2021-04-21 02:10:35.414854: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0421 02:10:35.415571 139761606117248 cross_device_ops.py:1321] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0421 02:10:35.415833 139761606117248 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 7500\n",
            "I0421 02:10:35.420794 139761606117248 config_util.py:552] Maybe overwriting train_steps: 7500\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0421 02:10:35.420996 139761606117248 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:546: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0421 02:10:35.478888 139761606117248 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:546: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/ODModel/armaps-od/records/train.record']\n",
            "I0421 02:10:35.496129 139761606117248 dataset_builder.py:163] Reading unweighted datasets: ['/content/ODModel/armaps-od/records/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/ODModel/armaps-od/records/train.record']\n",
            "I0421 02:10:35.496378 139761606117248 dataset_builder.py:80] Reading record datasets for input file: ['/content/ODModel/armaps-od/records/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0421 02:10:35.496480 139761606117248 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0421 02:10:35.496559 139761606117248 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0421 02:10:35.624112 139761606117248 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0421 02:10:35.655197 139761606117248 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0421 02:10:43.373054 139761606117248 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0421 02:10:47.536397 139761606117248 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0421 02:10:50.218924 139761606117248 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-04-21 02:10:52.927309: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-04-21 02:10:52.934276: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:11:12.412243 139759627253504 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:11:12.412648 139759627253504 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:11:12.412836 139759627253504 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:11:12.413004 139759627253504 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:11:12.413169 139759627253504 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:11:12.413331 139759627253504 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "2021-04-21 02:12:09.728102: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 829440000 exceeds 10% of free system memory.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0421 02:12:38.700524 139759627253504 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "2021-04-21 02:13:27.185852: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 829440000 exceeds 10% of free system memory.\n",
            "2021-04-21 02:13:27.882470: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 829440000 exceeds 10% of free system memory.\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqb33ihknpCs"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UBxLRR5RttK"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGtfi97VCMOp"
      },
      "source": [
        "Here we're going yo run the code through a loop that waits for checkpoints to evaluate. Once the evaluation finishes, you're going to see the message:\n",
        "\n",
        "`INFO:tensorflow:Waiting for new checkpoint at /content/ODModel/armaps-od/training/`\n",
        "\n",
        "Then you can stop the cell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR_ASWHFRvEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef2537c-86b2-46fe-b2d2-afcf51b0e34d"
      },
      "source": [
        "!python /content/ODModel/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --checkpoint_dir={model_dir}           ##This is passed to run ONLY EVALUATION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-21 02:13:44.342918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0421 02:13:53.389515 140502694037376 model_lib_v2.py:1063] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0421 02:13:53.389774 140502694037376 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0421 02:13:53.389847 140502694037376 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0421 02:13:53.389915 140502694037376 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0421 02:13:53.390104 140502694037376 model_lib_v2.py:1084] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2021-04-21 02:13:53.429083: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-21 02:13:53.463553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-21 02:13:53.525615: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-21 02:13:53.525687: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c2a0c1b62030): /proc/driver/nvidia/version does not exist\n",
            "2021-04-21 02:13:53.526571: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/ODModel/armaps-od/records/test.record']\n",
            "I0421 02:13:53.754291 140502694037376 dataset_builder.py:163] Reading unweighted datasets: ['/content/ODModel/armaps-od/records/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/ODModel/armaps-od/records/test.record']\n",
            "I0421 02:13:53.757390 140502694037376 dataset_builder.py:80] Reading record datasets for input file: ['/content/ODModel/armaps-od/records/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0421 02:13:53.757629 140502694037376 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0421 02:13:53.757699 140502694037376 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0421 02:13:53.770598 140502694037376 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0421 02:13:53.861499 140502694037376 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0421 02:13:58.238590 140502694037376 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0421 02:13:59.602224 140502694037376 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/ODModel/armaps-od/training/\n",
            "I0421 02:14:02.873697 140502694037376 checkpoint_utils.py:139] Waiting for new checkpoint at /content/ODModel/armaps-od/training/\n",
            "INFO:tensorflow:Found new checkpoint at /content/ODModel/armaps-od/training/ckpt-1\n",
            "I0421 02:14:02.876107 140502694037376 checkpoint_utils.py:148] Found new checkpoint at /content/ODModel/armaps-od/training/ckpt-1\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "2021-04-21 02:14:03.072061: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-04-21 02:14:03.076475: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:14:11.473603 140502694037376 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:14:11.474063 140502694037376 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:14:11.474288 140502694037376 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:14:11.474490 140502694037376 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:14:11.474673 140502694037376 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0421 02:14:11.474853 140502694037376 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0421 02:14:27.850968 140502694037376 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0421 02:14:27.856391 140502694037376 model_lib_v2.py:939] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0421 02:14:28.023486 140502694037376 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/utils/visualization_utils.py:617: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Performing evaluation on 57 images.\n",
            "I0421 02:14:34.999657 140502694037376 coco_evaluation.py:293] Performing evaluation on 57 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0421 02:14:35.000176 140502694037376 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0421 02:14:35.004052 140502694037376 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.38s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.09s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
            "INFO:tensorflow:Eval metrics at step 0\n",
            "I0421 02:14:35.482246 140502694037376 model_lib_v2.py:988] Eval metrics at step 0\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.000046\n",
            "I0421 02:14:35.487594 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Precision/mAP: 0.000046\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000250\n",
            "I0421 02:14:35.488719 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000250\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n",
            "I0421 02:14:35.489497 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0421 02:14:35.490511 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
            "I0421 02:14:35.491407 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Precision/mAP (medium): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.000053\n",
            "I0421 02:14:35.492193 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Precision/mAP (large): 0.000053\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.000000\n",
            "I0421 02:14:35.492856 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Recall/AR@1: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.005556\n",
            "I0421 02:14:35.493501 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Recall/AR@10: 0.005556\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.014815\n",
            "I0421 02:14:35.494115 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Recall/AR@100: 0.014815\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0421 02:14:35.494760 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
            "I0421 02:14:35.495336 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.014815\n",
            "I0421 02:14:35.496063 140502694037376 model_lib_v2.py:991] \t+ DetectionBoxes_Recall/AR@100 (large): 0.014815\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.674347\n",
            "I0421 02:14:35.496660 140502694037376 model_lib_v2.py:991] \t+ Loss/localization_loss: 0.674347\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 3.374202\n",
            "I0421 02:14:35.497204 140502694037376 model_lib_v2.py:991] \t+ Loss/classification_loss: 3.374202\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.609331\n",
            "I0421 02:14:35.497798 140502694037376 model_lib_v2.py:991] \t+ Loss/regularization_loss: 0.609331\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 4.657880\n",
            "I0421 02:14:35.498338 140502694037376 model_lib_v2.py:991] \t+ Loss/total_loss: 4.657880\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ODModel/models/research/object_detection/model_main_tf2.py\", line 113, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/ODModel/models/research/object_detection/model_main_tf2.py\", line 88, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1110, in eval_continuously\n",
            "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 215, in checkpoints_iterator\n",
            "    time.sleep(time_to_next_eval)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxvpnTruphye"
      },
      "source": [
        "### Training and validation Metrics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ZSdvMzRGsq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b54e04b-43d2-48a9-ce7d-e471f1a1298a"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/ODModel/armaps-od/training/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Launching TensorBoard..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R_znCjFXdhj"
      },
      "source": [
        "### Export the Inference Graph\n",
        "\n",
        "The below code cell adds a line to the tf_utils.py file. This is a temporary fix to a exporting issue occuring when using the OD API with Tensorflow 2. This code will be removed as soon as the OD Team puts out a fix.\n",
        "\n",
        "All credit goes to the Github users [Jacobsolawetz](https://github.com/Jacobsolawetz) and [ Tanner Gilbert](https://github.com/TannerGilbert), who provided this [temporary fix](https://github.com/tensorflow/models/issues/8841#issuecomment-657647648)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsrZNbomXfzA"
      },
      "source": [
        "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py') as f:\n",
        "    tf_utils = f.read()\n",
        "\n",
        "with open('/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py', 'w') as f:\n",
        "  # Set labelmap path\n",
        "  throw_statement = \"raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\"\n",
        "  tf_utils = tf_utils.replace(throw_statement, \"if not isinstance(x, str):\" + throw_statement)\n",
        "  f.write(tf_utils)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRJxDZ36XdKw"
      },
      "source": [
        "output_directory = 'inference_graph'\n",
        "\n",
        "!python /content/ODModel/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {model_dir} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_config_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ4nCG2QaUrk"
      },
      "source": [
        "##### Downloading weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqgiuAVsHFIK"
      },
      "source": [
        "!zip -r /content/ODModel/saved_model.zip /content/ODModel/inference_graph/saved_model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ecN2ZoXaWJp"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/ODModel/saved_model.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5gaL9ODnu-x"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnGFb9nleIJ8"
      },
      "source": [
        "###  Testing the trained model\n",
        "\n",
        "Based on [Object Detection API Demo](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) and [Inference from saved model tf2 colab](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn8I2sdaTqww"
      },
      "source": [
        "%cd /content/ODModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn1qzpWKRG0R"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/hugozanini/object-detection/master/inferenceutils.py\n",
        "from inferenceutils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD4pogqTnRvv"
      },
      "source": [
        "##### Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiqxI1qK2Smu"
      },
      "source": [
        "output_directory = 'inference_graph/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iejp6C20mndZ"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(f'/content/ODModel/{output_directory}/saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geqTTdirnU6K"
      },
      "source": [
        "##### Selecting the images to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCA1RWcrl-Ea"
      },
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('/content/ODModel/armaps-od/images/test_labels.csv')\n",
        "images = list(test['filename'][0:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXd0Bh9Go0C8"
      },
      "source": [
        "##### Doing inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi5oxETyk8PP"
      },
      "source": [
        "#images = ['canguru-1.jpeg', 'canguru-2.jpeg', 'canguru-3.jpeg']\n",
        "\n",
        "for image_name in images:\n",
        "  \n",
        "  image_np = load_image_into_numpy_array('/content/ODModel/armaps-od/images/test/' + image_name)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsQsFG_jnw34"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPtldBFZZkrk"
      },
      "source": [
        "### References\n",
        "\n",
        "[0] Tanner, G. (2020, July 27). Tensorflow Object Detection with Tensorflow 2: Creating a custom model. Retrieved December 28, 2020, from https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model\n",
        "\n",
        "---\n",
        "\n",
        "[1] Rafiq, H. (2020, December 13). Image Object Detection - TensorFlow 2 Object Detection API. Retrieved December 28, 2020, from https://medium.com/swlh/image-object-detection-tensorflow-2-object-detection-api-af7244d4c34e\n",
        "\n",
        "---\n",
        "\n",
        "[2] TensorFlow 2 Detection Model Zoo. (2020, September 09). Tensorflow/models. Retrieved December 28, 2020, from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "\n",
        "---\n",
        "\n",
        "[3] Tensorflow 2 Models Configs. (2020, August 11). Tensorflow/models. Retrieved December 28, 2020, from https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2\n",
        "\n",
        "---\n",
        "[4] Solawetz, J. (2020, December 09). How to Train YOLOv4 on a Custom Dataset. Retrieved December 28, 2020, from https://blog.roboflow.com/training-yolov4-on-a-custom-dataset/\n",
        "\n",
        "---\n",
        "\n",
        "[5] Google Colaboratory. (n.d.). Retrieved January 13, 2021, from https://colab.research.google.com/github/cloud-annotations/google-colab-training/blob/master/object_detection.ipynb#:~:text=The%20TensorFlow%20Object%20Detection%20API%20relies%20on%20what%20are%20called,like%20Python%2C%20Java%20or%20C.\n"
      ]
    }
  ]
}